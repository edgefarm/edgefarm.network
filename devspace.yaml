version: v2beta1
name: edgefarm-network

imports:
  - path: ./config.yaml

vars:
  MAIN_NATS_IP:
    command: |-
      #!/bin/bash
      set -e
      LOCAL=$(kubectl get secrets -n default cluster-info -o jsonpath='{.data.kindCluster}' | base64 -d)
      if [ "$LOCAL" == "true" ]; then
        IP=$(kubectl get secrets -n default cluster-info -o jsonpath='{.data.clusterIP}' | base64 -d)
        echo ${IP}
      else
        echo "nats-main.nats.svc.cluster.local"
        IP=$(kubectl get nodes $(kubectl get pods -n nats nats-main-0 -o jsonpath='{.spec.nodeName}') -o jsonpath='{.status.addresses[?(@.type=="InternalIP")].address}')
        echo ${IP}
      fi

commands:
  help: |-
    #!/bin/bash
    set -e
    GREEN='\033[0;32m'
    BRED='\033[3;31m'
    BGREEN='\033[1;32m'
    GREY='\033[0;36m'
    BOLD='\033[1m'
    NC='\033[0m' # No Color
    echo -e "${BGREEN}Usage of ${BRED}edgefarm.network:${NC}"
    echo -e "${GREEN} EdgeFarm related commands:${NC}"
    echo -e "${BOLD}  devspace run-pipeline deploy-network                ${GREY}Deploy edgefarm-network to the cluster${NC}"
    echo -e "${BOLD}  devspace run-pipeline purge-network                 ${GREY}Delete edgefarm-network from the cluster${NC}"

functions:
  wait_for_pod: |-
    #!/bin/bash
    set -e
    echo "wait for pod $1 (ns: $2)"
    until kubectl wait --for=condition=ready pod -n $2 $1 --timeout=60s 2>/dev/null; do echo -n "." && sleep 2; done

pipelines:
  deploy-network: |-
    run_pipelines deploy-cloud-network
    run_pipelines deploy-edge-network
    run_pipelines deploy-example-stream

  deploy-cloud-network: |-
    #!/bin/bash
    set -e
    COLOR='\033[0;93m'
    NC='\033[0m'
    kubectl label node -l '!node-role.kubernetes.io/control-plane' edgefarm.io/nats-main=true --overwrite

    create_deployments servicemonitors-crd
    create_deployments nats-main
    wait_for_pod "-l app.kubernetes.io/instance=nats-main,app.kubernetes.io/name=nats" nats

  deploy-example-stream: |-
    #!/bin/bash
    set -e
    COLOR='\033[0;93m'
    NC='\033[0m'
    echo -e "${COLOR}Creating example jetstream in domain: main${NC}"
    cat <<EOF | kubectl apply -n nats -f -
    kind: ConfigMap
    apiVersion: v1
    metadata:
      name: example-stream
    data:
      example.json: |
        {
          "config": {
            "name": "example",
            "subjects": [
              "example.>"
            ],
            "retention": "limits",
            "max_consumers": -1,
            "max_msgs_per_subject": -1,
            "max_msgs": -1,
            "max_bytes": 10485760,
            "max_age": 0,
            "max_msg_size": -1,
            "storage": "file",
            "discard": "old",
            "num_replicas": 1,
            "duplicate_window": 120000000000,
            "sealed": false,
            "deny_delete": false,
            "deny_purge": false,
            "allow_rollup_hdrs": false
          }
        }
    ---
    kind: Job
    apiVersion: batch/v1
    metadata:
      name: create-example-stream
      labels:
        app.kubernetes.io/name: create-example-stream
    spec:
      template:
        spec:
          containers:
          - name: create-example-stream
            image: natsio/nats-box:0.13.2
            command:
            - /bin/sh
            - -c
            - "/usr/local/bin/nats stream create --config /config/example.json --user ${NATS_TOKEN} -s nats://nats-main.nats.svc.cluster.local:4222 --domain main && /usr/local/bin/nats stream ls --user ${NATS_TOKEN} -s nats://nats-main.nats.svc.cluster.local:4222 --domain main"
            volumeMounts:
            - name: example-stream
              mountPath: /config
          restartPolicy: Never
          volumes:
          - name: example-stream
            configMap:
              name: example-stream
      backoffLimit: 4
    EOF
    kubectl wait --for=condition=complete job/create-example-stream -n nats --timeout=60s
    kubectl logs job/create-example-stream -n nats
    kubectl delete job create-example-stream -n nats

  deploy-edge-network: |-
    #!/bin/bash
    set -e
    create_deployments leaf-nats

  purge-network: |-
    #!/bin/bash
    set -e
    COLOR='\033[0;93m'
    NC='\033[0m'
    purge_deployments nats-main
    purge_deployments leaf-nats

deployments:
  nats-main:
    helm:
      chart:
        name: nats
        repo: https://nats-io.github.io/k8s/helm/charts/
      values:
        nats:
          # externalAccess is enabled because to give access to external devices through kind port mapping
          externalAccess: true
          advertise: false
          serviceAccount:
            create: false
          jetstream:
            enabled: true
            domain: main
            fileStorage:
              size: ${MAIN_NATS_MAX_STORAGE}
        exporter:
          enabled: true
          image: natsio/prometheus-nats-exporter:latest
          pullPolicy: IfNotPresent
          serviceMonitor:
            enabled: true
        namespaceOverride: "nats"
        podDisruptionBudget:
          enabled: false
        nodeSelector: { edgefarm.io/nats-main: "true" }
        cluster:
          # cluster is disabled in local setup
          enabled: false
          #replicas: 3
          noAdvertise: true
        leafnodes:
          enabled: true
          noAdvertise: true
        natsbox:
          enabled: false
        auth:
          enabled: true
          # fixed token to access the nats cluster
          token: ${NATS_TOKEN}
    namespace: nats

  servicemonitors-crd:
    kubectl:
      manifests:
        - https://raw.githubusercontent.com/grafana/agent/main/production/operator/crds/monitoring.coreos.com_servicemonitors.yaml

  leaf-nats:
    namespace: nats
    helm:
      chart:
        name: leaf-nats
        path: ./charts/leaf-nats
      values:
        fullnameOverride: leaf-nats
        config:
          nats:
            host: ${MAIN_NATS_IP}
            token: ${NATS_TOKEN}
          targetNodeGroupLabels:
            - matchLabels:
                network.edgefarm.io/edge: ""
